{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K20Xm (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, minmax_scale, maxabs_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "import pep2space as pep\n",
    "\n",
    "MAX_POS=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Coordinates\n",
    "**straight** - predict each coordinate.\n",
    "\n",
    "- naive approach: surround sequences by null symbols.\n",
    "\n",
    "- \"omega loops\": first and last amino acids depends on each other other. It is better than the naive approach:\n",
    "<img src=\"loss/loss_x_dense_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "- positional: add position for each amino acid to each dense layer. It does a little change:\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "**difference** - ??? (predict differences between neighbour coordinates)\n",
    "\n",
    "\n",
    "### Amino acid transformations\n",
    "**one-hot** - code each amino acid as a 20-dimensional vector with 1 at the index of the corresponding amino acid.\n",
    "\n",
    "**kidera** - worked worse than one-hot.\n",
    "\n",
    "**embeddings** - ??? (infer embeddings on the overall data—é)\n",
    "\n",
    "\n",
    "### Feature generation\n",
    "**window** - sliding window, predict the coordinate in the centre of the window.\n",
    "\n",
    "**directional / bidirectional** - ??? (RNN)\n",
    "\n",
    "\n",
    "## Feature preprocessing\n",
    "\n",
    "### Scale the data\n",
    "\n",
    "Scale the data to [0,1]. Tested on models with [128,64] dense layers, 4-4 window size, 2000 iterations.\n",
    "- per column - scale each column independently:\n",
    "```\n",
    "MSE:\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.43089   *\n",
    "    can - 0.0978544\n",
    "MaxAbs:\n",
    "    cdr - 1.95208   **\n",
    "    can - 0.0967865\n",
    "```\n",
    "- overall - scale the overall matrix:\n",
    "```\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.27693   *\n",
    "    can - 0.105339\n",
    "MaxAbs:\n",
    "    cdr - 1.96837   **\n",
    "    can - 0.0973526\n",
    "```\n",
    "\n",
    "### Pre-clustering\n",
    "\n",
    "Assign weights accroding to the clusters' sizes. Cluster weight = `ln(cluster size) / ln(minimal cluster size)`. Clustering helps:\n",
    "\n",
    "<img src=\"loss/loss_x_dense_onehot_noscale_clust5.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "## Learning\n",
    "\n",
    "### Straightforward learning\n",
    "\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### Change learning rate\n",
    "\n",
    "Factor 0.3, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor03_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 6\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience6_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### Add putative sequences to batches\n",
    "\n",
    "??? (to add noise)\n",
    "\n",
    "\n",
    "## Post-analysis\n",
    "\n",
    "### Ensembling\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1-dimensional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check if scaling works better than no-transformation\n",
    "\n",
    "### Per-column scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hist_list = {}\n",
    "# model_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# m_0 = pepm.train_model(MAX_POS, 5, \"x\", [128,64], 4, 4, 200, hist_list, model_list)\n",
    "# m_1 = pepm.train_model(MAX_POS, 5, \"x\", [128,64,64], 6, 6, 200, hist_list, model_list, \"col\", \"abs\")\n",
    "# m_2 = pepm.train_model(MAX_POS, 5, \"x\", [128,64], 4, 4, 500, hist_list, model_list, \"col\", \"abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "# df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "# X_cdr, y_cdr = to_vec_onehot(df_cdr, 4, 4)\n",
    "# X_can, y_can = to_vec_onehot(df_can, 4, 4)\n",
    "# print(\"cdr\", mean_squared_error(y_cdr, m_0.predict(X_cdr)))\n",
    "# print(\"can\", mean_squared_error(y_can, m_0.predict(X_can)))\n",
    "\n",
    "# # print(\"cdr\", tr_pred_col(\"data/cdr_coord_x.csv.gz\", MinMaxScaler, m_mm_col, 4, 4))\n",
    "# # print(\"can\", tr_pred_col(\"data/can_coord_x.csv.gz\", MinMaxScaler, m_mm_col, 4, 4))\n",
    "\n",
    "# print(\"cdr\", tr_pred_col(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler, best_models_list[\"left4_right4.128-64-64.col_abs.clust_5\"], 4, 4))\n",
    "# print(\"can\", tr_pred_col(\"data/can_coord_x.csv.gz\", MaxAbsScaler, best_models_list[\"left4_right4.128-64-64.col_abs.clust_5\"], 4, 4))\n",
    "\n",
    "\n",
    "# # batch=64\n",
    "# # cdr 1.47792\n",
    "# # can 0.113192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overall scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hist_scale = {}\n",
    "# m_no = train_models(\"x\", [128,64], 4, 4, 2000, hist_scale)\n",
    "# m_mm_all = train_models_scale_all(\"x\", [128,64], 4, 4, 2000, hist_scale, \"mm\")\n",
    "# m_abs_all = train_models_scale_all(\"x\", [128,64], 4, 4, 2000, hist_scale, \"abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "# df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "# X_cdr, y_cdr = to_vec_onehot(df_cdr, 4, 4)\n",
    "# X_can, y_can = to_vec_onehot(df_can, 4, 4)\n",
    "# print(\"cdr\", mean_squared_error(y_cdr, m_no.predict(X_cdr)))\n",
    "# print(\"can\", mean_squared_error(y_can, m_no.predict(X_can)))\n",
    "\n",
    "# print(\"cdr\", tr_pred(\"data/cdr_coord_x.csv.gz\", MinMaxScaler(), m_mm_all))\n",
    "# print(\"can\", tr_pred(\"data/can_coord_x.csv.gz\", MinMaxScaler(), m_mm_all))\n",
    "\n",
    "# print(\"cdr\", tr_pred(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all))\n",
    "# print(\"can\", tr_pred(\"data/can_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all))\n",
    "\n",
    "\n",
    "# # cdr 1.61775\n",
    "# # can 0.0993797\n",
    "# # cdr 2.27693\n",
    "# # can 0.105339\n",
    "# # cdr 1.96837\n",
    "# # can 0.0973526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find which windows and layer sizes are the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_pos.l4_r4.128-64.no_no.onehot\t"
     ]
    }
   ],
   "source": [
    "pep.model = reload(pep.model)\n",
    "\n",
    "best_models = [(4,4)]\n",
    "best_layers = [[128, 64]]\n",
    "\n",
    "best_hist = {}\n",
    "best_models_list = {}\n",
    "\n",
    "for l,r in best_models:\n",
    "    for layers in best_layers:\n",
    "        pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, model_type=\"dense_pos\")\n",
    "        pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, features = \"omega\", model_type=\"dense_pos\")\n",
    "        pep.model.train_model(MAX_POS, 5, \"x\", layers, l, r, 1200, best_hist, best_models_list, model_type=\"dense_pos\")\n",
    "        pep.model.train_model(MAX_POS, 5, \"x\", layers, l, r, 1200, best_hist, best_models_list, features = \"omega\", model_type=\"dense_pos\")\n",
    "        \n",
    "  \n",
    "# factor=0.2, patience=3, cooldown=1, min_lr=0.0005\n",
    "# dense_pos.l4_r4.128-64.no_no.onehot\t1.53412900944\n",
    "# dense_pos.l4_r4.128-64.no_no.omega\t1.56518625436\n",
    "# dense_pos.l4_r4.128-64.no_no.onehot.clust_5\t1.59467022459\n",
    "# dense_pos.l4_r4.128-64.no_no.omega.clust_5\t1.53090134249\n",
    "\n",
    "# factor=0.2, patience=3, cooldown=0, min_lr=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# model = best_models_list[\"left4_right4.128-64.no_no.onehot\"]\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 1\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:10]\n",
    "\n",
    "# for i, h in enumerate(sorted(cur_hist.keys())):\n",
    "for i, (h, _) in enumerate(best_models):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor02_patience3_cooldown1_1200it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_pred(df, pred, ax, title):\n",
    "    trans = pred.reshape((len(df),12))\n",
    "    for i in range(len(df)):\n",
    "        ax.plot(range(12), df.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "        ax.plot(range(12), trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.8, label=\"pred\")\n",
    "    ax.set_title(title)\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "\n",
    "cur_hist = best_hist_scale\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:10]\n",
    "\n",
    "# for i, h in enumerate(sorted(cur_hist.keys())):\n",
    "for i, (h, _) in enumerate(best_models):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/loss_dense_onehot_scale_batch64_search_top10_lr2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predicted and real coordinates\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "X_cdr, y_cdr = to_vec_onehot(df_cdr, 4, 4)\n",
    "X_can, y_can = to_vec_onehot(df_can, 4, 4)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "\n",
    "pred = m_no.predict(X_cdr)\n",
    "# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MinMaxScaler, m_mm_col)\n",
    "# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler, m_abs_col)\n",
    "# _, pred = get_true_pred_all(\"data/cdr_coord_x.csv.gz\", MinMaxScaler(), m_mm_all)\n",
    "_, pred = get_true_pred_all(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all)\n",
    "plot_pred(df_cdr, pred, ax[0], \"CDR\")\n",
    "\n",
    "pred = m_no.predict(X_can)\n",
    "# _, pred = get_true_pred_col(\"data/can_coord_x.csv.gz\", MinMaxScaler, m_mm_col)\n",
    "# _, pred = get_true_pred_col(\"data/can_coord_x.csv.gz\", MaxAbsScaler, m_abs_col)\n",
    "# _, pred = get_true_pred_all(\"data/can_coord_x.csv.gz\", MinMaxScaler(), m_mm_all)\n",
    "_, pred = get_true_pred_all(\"data/can_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all)\n",
    "plot_pred(df_can, pred, ax[1], \"Canonical\")\n",
    "\n",
    "# plt.savefig(\"pred_dense_onehot_no.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_mm_col.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_mm_all.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_abs_col.png\")\n",
    "plt.savefig(\"pred/pred_dense_onehot_abs_all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-dimensional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_models(coord, layers, left_window, right_window, n_epochs, hist):\n",
    "    model_name = \"left\" + str(left_window) + \"_right\" + str(right_window)\n",
    "    if model_name not in hist:\n",
    "        df_cdr = pd.read_csv(\"data/cdr_coord_\" + coord[0] + \".csv.gz\")\n",
    "        df_can = pd.read_csv(\"data/can_coord_\" + coord[0] + \".csv.gz\")\n",
    "        \n",
    "        df_cdr_add = pd.read_csv(\"data/cdr_coord_\" + coord[1] + \".csv.gz\")\n",
    "        df_can_add = pd.read_csv(\"data/can_coord_\" + coord[1] + \".csv.gz\")\n",
    "\n",
    "        X_can, y_can = to_vec_onehot(df_can, df_can_add, left_window, right_window)\n",
    "        X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, left_window, right_window)\n",
    "\n",
    "        model = dense_model((20*(right_window+left_window+1),), 2, layers)\n",
    "\n",
    "        hist[model_name] = model.fit(X_can, y_can, batch_size=128, epochs=n_epochs, verbose=0, validation_data=(X_cdr, y_cdr))\n",
    "\n",
    "\n",
    "# hist = {}\n",
    "# for left_window in range(8):\n",
    "#     for right_window in range(8):\n",
    "#         train_models(\"x\", left_window, right_window, 2000, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_models = [(3,3), (4,4), (5,5), (6,6)]\n",
    "\n",
    "best_hist = {}\n",
    "for l,r in best_models:\n",
    "    train_models([\"x\", \"y\"], [128,64], l, r, 2000, best_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 10\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:8]\n",
    "\n",
    "for i, (h, _) in enumerate(sorted(best_models)):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/loss_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "\n",
    "df_cdr_add = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "df_can_add = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "\n",
    "X_can, y_can = to_vec_onehot(df_can, df_can_add, 5, 5)\n",
    "X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, 5, 5)\n",
    "\n",
    "model = dense_model((20*(5+5+1),), 2, [128, 64])\n",
    "\n",
    "model.fit(X_can, y_can, batch_size=128, epochs=2000, verbose=0, validation_data=(X_cdr, y_cdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predicted and real coordinates\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "\n",
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[0][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][0].set_title(\"CDR X\")\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[1][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][0].set_title(\"CDR Y\")\n",
    "\n",
    "    \n",
    "pred = model.predict(X_can)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[0][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][1].set_title(\"Canonical X\")\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[1][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][1].set_title(\"Canonical Y\")\n",
    "\n",
    "plt.savefig(\"pred/pred_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "pred_x[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
