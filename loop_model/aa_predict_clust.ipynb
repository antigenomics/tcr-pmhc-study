{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,floatX=float32,device=gpu,lib.cnmem=.95,scan.allow_gc=False\"\n",
    "import theano\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, minmax_scale, maxabs_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\") \n",
    "\n",
    "import pep2space\n",
    "\n",
    "MAX_POS=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Coordinates and models\n",
    "**window** - sliding window, predict the coordinate in the centre of the window.\n",
    "\n",
    "**directional / bidirectional** - recurrent neural networks.\n",
    "\n",
    "**straight** - predict each coordinate.\n",
    "\n",
    "**difference** - predict differences between neighbour coordinates\n",
    "\n",
    "**window + straight** - predict each coordinate.\n",
    "\n",
    "### 1.1. Naive approach\n",
    "\n",
    "Surround sequences by null symbols.\n",
    "\n",
    "### 1.2. \"Omega loops\"\n",
    "\n",
    "First and last amino acids depends on each other other. It is better than the naive approach:\n",
    "<img src=\"loss/loss_x_dense_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "### 1.3 Positional / length-positional\n",
    "\n",
    "Add position or position/length for each amino acid to each dense layer. It helps:\n",
    "\n",
    "<img src=\"loss/comparison/loss_x_dense_comparison_1500it.png\" width=\"80%\">\n",
    "\n",
    "Interstinegly enough, if we train the model on CDRs and predict putative ones than the pos-len modification helps a lot:\n",
    "\n",
    "<img src=\"loss/loss_dense_changeCDRs_1500it.png\" width=\"80%\">\n",
    "\n",
    "### 1.4. Recurrent models\n",
    "\n",
    "GRU models, 1500 iterations:\n",
    "<img src=\"loss/comparison/loss_x_gru_comparison_1500it.png\" width=\"80%\">\n",
    "\n",
    "### 1.5. Difference among coordinates (left-to-right)\n",
    "\n",
    "Due to the iterative nature the error is aggreageted through the sequence.\n",
    "\n",
    "<img src=\"pred/pred_x_diff_coords.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "## 2. Amino acid transformations\n",
    "**one-hot** - code each amino acid as a 20-dimensional vector with 1 at the index of the corresponding amino acid.\n",
    "\n",
    "**kidera** - worked worse than one-hot.\n",
    "\n",
    "**embeddings** - ??? (infer embeddings on the overall data—é)\n",
    "\n",
    "**two-hot** - one-hot vector + one-hot vector for target amino acid.\n",
    "\n",
    "\n",
    "## 3. Feature preprocessing\n",
    "\n",
    "### 3.1. Scale the data\n",
    "\n",
    "Scale the data to [0,1]. Tested on models with [128,64] dense layers, 4-4 window size, 2000 iterations.\n",
    "- per column - scale each column independently:\n",
    "```\n",
    "MSE:\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.43089   *\n",
    "    can - 0.0978544\n",
    "MaxAbs:\n",
    "    cdr - 1.95208   **\n",
    "    can - 0.0967865\n",
    "```\n",
    "- overall - scale the overall matrix:\n",
    "```\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.27693   *\n",
    "    can - 0.105339\n",
    "MaxAbs:\n",
    "    cdr - 1.96837   **\n",
    "    can - 0.0973526\n",
    "```\n",
    "\n",
    "### 3.2. Pre-clustering\n",
    "\n",
    "Assign weights accroding to the clusters' sizes. Cluster weight = `ln(cluster size) / ln(minimal cluster size)`. Clustering helps:\n",
    "\n",
    "<img src=\"loss/loss_x_dense_onehot_noscale_clust5.png\" width=\"90%\">\n",
    "\n",
    "However prediction with clustering is a little bit off due to the small weights on big clusters:\n",
    "\n",
    "<img src=\"pred/pred_strange_with_clustering.png\" width=\"110%\">\n",
    "\n",
    "\n",
    "### 3.3. Pre-clustering with fading weights on clusters\n",
    "\n",
    "???\n",
    "???\n",
    "\n",
    "\n",
    "## 4. Learning\n",
    "\n",
    "### 4.1. Straightforward learning\n",
    "\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### 4.2. Change learning rate\n",
    "\n",
    "Factor 0.3, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor03_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 6\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience6_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### 4.3. Add putative sequences to batches\n",
    "\n",
    "??? (to add noise)\n",
    "\n",
    "\n",
    "## 5. Post-analysis\n",
    "\n",
    "### 5.1. Ensembling\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1-dimensional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find which windows and layer sizes are the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-0805dd482161>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0805dd482161>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    print(best_hist.keys())\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pep2space import model as pepmodel\n",
    "from pep2space import eval as pepeval\n",
    "pep2space = importlib.reload(pep2space)\n",
    "pepeval = importlib.reload(pep2space.eval)\n",
    "pepmodel = importlib.reload(pep2space.model)\n",
    "\n",
    "best_models = [(4,4), (6,6)]\n",
    "best_layers = [[128, 64]]\n",
    "\n",
    "best_hist = {}\n",
    "best_models_list = {}\n",
    "best_models_loss = pd.DataFrame()\n",
    "\n",
    "for l,r in best_models:\n",
    "    for layers in best_layers:\n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense\")\n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense_pos\")\n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense_poslen\")\n",
    "        \n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 5, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense\")\n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 5, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense_pos\")\n",
    "        _, best_models_loss = pepmodel.train_model(MAX_POS, 5, \"x\", layers, l, r, 1500, \n",
    "                                                   best_hist, best_models_list, best_models_loss, \n",
    "                                                   features = \"omega\", model_type=\"dense_poslen\")\n",
    "        \n",
    "print(best_hist.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_win, right_win = 4, 4\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "X_can, y_can = pep2space.preprocess.onehot_omega(df_cdr, left_win, right_win, MAX_POS, True)\n",
    "X_cdr, y_cdr = pep2space.preprocess.onehot_omega(df_can, left_win, right_win, MAX_POS, True)\n",
    "\n",
    "y_can_diff_forw = pep2space.preprocess.diff_to_abs(max_pos=MAX_POS, rev=False, y=y_can)\n",
    "y_can_diff_back = -pep2space.preprocess.diff_to_abs(max_pos=MAX_POS, rev=True, y=y_can)\n",
    "\n",
    "y_cdr_diff_forw = pep2space.preprocess.diff_to_abs(max_pos=MAX_POS, rev=False, y=y_cdr)\n",
    "y_cdr_diff_back = -pep2space.preprocess.diff_to_abs(max_pos=MAX_POS, rev=True, y=y_cdr)\n",
    "\n",
    "\n",
    "input_shape = (left_win+right_win+1, len(pep2space.preprocess.CHARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_28 (InputLayer)            (None, 9, 20)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_29 (InputLayer)            (None, 9, 20)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)       (None, 64)            20800                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_35 (Dense)                 (None, 1)             65                                           \n",
      "____________________________________________________________________________________________________\n",
      "dense_36 (Dense)                 (None, 1)             65                                           \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_35 (PReLU)               (None, 1)             1                                            \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_36 (PReLU)               (None, 1)             1                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 1)             3                                            \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_37 (PReLU)               (None, 1)             1                                            \n",
      "====================================================================================================\n",
      "Total params: 20,936.0\n",
      "Trainable params: 20,808.0\n",
      "Non-trainable params: 128.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: an index can only have a single Ellipsis (`...`); replace all but one with slices (`:`).\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: an index can only have a single Ellipsis (`...`); replace all but one with slices (`:`).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 arrays but instead got the following list of 3 arrays: [array([[[False,  True, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ..., \n        [False...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dd64b4d57b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           validation_data = ([X_cdr, X_cdr[..., ::-1, ...], \n\u001b[1;32m      7\u001b[0m                               np.array([float((x % MAX_POS) + 1) / MAX_POS for x in range(X_cdr.shape[0])])], \n\u001b[0;32m----> 8\u001b[0;31m                              [y_cdr_diff_forw, y_cdr_diff_back, y_cdr]))\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                                     exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1296\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                  \u001b[0;34m'the following list of '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                  \u001b[0;34m' arrays: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                  '...')\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 arrays but instead got the following list of 3 arrays: [array([[[False,  True, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ..., \n        [False..."
     ]
    }
   ],
   "source": [
    "pepmodel = importlib.reload(pep2space.model)\n",
    "\n",
    "model = pepmodel.diff_model(input_shape, 1, ([64,64],[32]))\n",
    "model.fit([X_can, X_can[..., ::-1, ...], np.array([float((x % MAX_POS) + 1) / MAX_POS for x in range(X_can.shape[0])])], \n",
    "          [y_can_diff_forw, y_can_diff_back, y_can], batch_size=32, epochs=50, verbose=2,\n",
    "          validation_data = ([X_cdr, X_cdr[..., ::-1, ...], \n",
    "                              np.array([float((x % MAX_POS) + 1) / MAX_POS for x in range(X_cdr.shape[0])])], \n",
    "                             [y_cdr_diff_forw, y_cdr_diff_back, y_cdr]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "fig.set_figwidth(18)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.4)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 5\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:10]\n",
    "\n",
    "cmap = plt.get_cmap('jet')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(best_models))]\n",
    "\n",
    "for i, (h, _) in enumerate(sorted(best_models, key=lambda x:x[0])):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h, c=colors[i])\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h, c=colors[i])\n",
    "    \n",
    "best_models_loss.sort_values(\"model\", inplace=True)\n",
    "ax[2] = sns.boxplot(y = \"val_loss\", x = \"model\", data = best_models_loss)\n",
    "ax[2].set_xticklabels(ax[2].get_xticklabels(), rotation=90)\n",
    "    \n",
    "ax[0].set_title(\"loss (cdr)\")\n",
    "ax[1].set_title(\"val (can)\")\n",
    "ax[2].set_title(\"boostrapped loss\")\n",
    "ax[0].legend(bbox_to_anchor=(2, -.2), loc='upper right', ncol = 2)\n",
    "\n",
    "plt.savefig(\"loss/loss_dense_changeCDRs_1500it.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = best_models_list[\"dense.l4_r4.128-64.no_no.omega\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_pred(df, pred, ax, title):\n",
    "    trans = pred.reshape((len(df),MAX_POS))\n",
    "    for i in range(len(df)):\n",
    "        ax.plot(range(MAX_POS), df.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "        ax.plot(range(MAX_POS), trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.8, label=\"pred\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "    \n",
    "# Predicted and real coordinates\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "X_cdr, y_cdr = pep2space.preprocess.onehot_omega(df_cdr, 4, 4, MAX_POS, False)\n",
    "X_can, y_can = pep2space.preprocess.onehot_omega(df_can, 4, 4, MAX_POS, False)\n",
    "\n",
    "# X_cdr =  [X_cdr, \n",
    "#           np.array([float((x % max_pos) + 1) / MAX_POS for x in range(X_cdr.shape[0])]), \n",
    "#           np.full((X_cdr.shape[0],1), MAX_POS)]\n",
    "\n",
    "# X_can =  [X_can, \n",
    "#           np.array([float((x % max_pos) + 1) / MAX_POS for x in range(X_can.shape[0])]), \n",
    "#           np.full((X_can.shape[0],1), MAX_POS)]\n",
    "\n",
    "pred = model.predict(X_cdr)\n",
    "# pred = pep2space.preprocess.diff_to_abs(pred, MAX_POS)\n",
    "plot_pred(df_cdr, pred, ax[0], \"CDR\")\n",
    "\n",
    "pred = model.predict(X_can)\n",
    "# pred = pep2space.preprocess.diff_to_abs(pred, MAX_POS)\n",
    "plot_pred(df_can, pred, ax[1], \"Canonical\")\n",
    "\n",
    "plt.savefig(\"pred/pred_x_dense_changeCDRs_coord.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-dimensional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_models(coord, layers, left_window, right_window, n_epochs, hist):\n",
    "    model_name = \"left\" + str(left_window) + \"_right\" + str(right_window)\n",
    "    if model_name not in hist:\n",
    "        df_cdr = pd.read_csv(\"data/cdr_coord_\" + coord[0] + \".csv.gz\")\n",
    "        df_can = pd.read_csv(\"data/can_coord_\" + coord[0] + \".csv.gz\")\n",
    "        \n",
    "        df_cdr_add = pd.read_csv(\"data/cdr_coord_\" + coord[1] + \".csv.gz\")\n",
    "        df_can_add = pd.read_csv(\"data/can_coord_\" + coord[1] + \".csv.gz\")\n",
    "\n",
    "        X_can, y_can = to_vec_onehot(df_can, df_can_add, left_window, right_window)\n",
    "        X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, left_window, right_window)\n",
    "\n",
    "        model = dense_model((20*(right_window+left_window+1),), 2, layers)\n",
    "\n",
    "        hist[model_name] = model.fit(X_can, y_can, batch_size=128, epochs=n_epochs, verbose=0, validation_data=(X_cdr, y_cdr))\n",
    "\n",
    "\n",
    "# hist = {}\n",
    "# for left_window in range(8):\n",
    "#     for right_window in range(8):\n",
    "#         train_models(\"x\", left_window, right_window, 2000, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_models = [(3,3), (4,4), (5,5), (6,6)]\n",
    "\n",
    "best_hist = {}\n",
    "for l,r in best_models:\n",
    "    train_models([\"x\", \"y\"], [128,64], l, r, 2000, best_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 10\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:8]\n",
    "\n",
    "for i, (h, _) in enumerate(sorted(best_models)):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/loss_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "\n",
    "df_cdr_add = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "df_can_add = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "\n",
    "X_can, y_can = to_vec_onehot(df_can, df_can_add, 5, 5)\n",
    "X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, 5, 5)\n",
    "\n",
    "model = dense_model((20*(5+5+1),), 2, [128, 64])\n",
    "\n",
    "model.fit(X_can, y_can, batch_size=128, epochs=2000, verbose=0, validation_data=(X_cdr, y_cdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predicted and real coordinates\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "\n",
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[0][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][0].set_title(\"CDR X\")\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[1][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][0].set_title(\"CDR Y\")\n",
    "\n",
    "    \n",
    "pred = model.predict(X_can)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[0][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][1].set_title(\"Canonical X\")\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[1][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][1].set_title(\"Canonical Y\")\n",
    "\n",
    "plt.savefig(\"pred/pred_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "pred_x[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
