{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,floatX=float32,device=gpu,lib.cnmem=.95,scan.allow_gc=False\"\n",
    "import theano\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, minmax_scale, maxabs_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "import pep2space\n",
    "\n",
    "MAX_POS=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Coordinates\n",
    "**straight** - predict each coordinate.\n",
    "\n",
    "- naive approach: surround sequences by null symbols.\n",
    "\n",
    "- \"omega loops\": first and last amino acids depends on each other other. It is better than the naive approach:\n",
    "<img src=\"loss/loss_x_dense_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "- positional: add position for each amino acid to each dense layer. It does a little change:\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "**difference** - ??? (predict differences between neighbour coordinates)\n",
    "\n",
    "\n",
    "### Amino acid transformations\n",
    "**one-hot** - code each amino acid as a 20-dimensional vector with 1 at the index of the corresponding amino acid.\n",
    "\n",
    "**kidera** - worked worse than one-hot.\n",
    "\n",
    "**embeddings** - ??? (infer embeddings on the overall data—é)\n",
    "\n",
    "\n",
    "### Feature generation\n",
    "**window** - sliding window, predict the coordinate in the centre of the window.\n",
    "\n",
    "**directional / bidirectional** - ??? (RNN)\n",
    "\n",
    "\n",
    "## Feature preprocessing\n",
    "\n",
    "### Scale the data\n",
    "\n",
    "Scale the data to [0,1]. Tested on models with [128,64] dense layers, 4-4 window size, 2000 iterations.\n",
    "- per column - scale each column independently:\n",
    "```\n",
    "MSE:\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.43089   *\n",
    "    can - 0.0978544\n",
    "MaxAbs:\n",
    "    cdr - 1.95208   **\n",
    "    can - 0.0967865\n",
    "```\n",
    "- overall - scale the overall matrix:\n",
    "```\n",
    "no scale:\n",
    "    cdr - 1.61775   ***\n",
    "    can - 0.0993797\n",
    "MinMax:\n",
    "    cdr - 2.27693   *\n",
    "    can - 0.105339\n",
    "MaxAbs:\n",
    "    cdr - 1.96837   **\n",
    "    can - 0.0973526\n",
    "```\n",
    "\n",
    "### Pre-clustering\n",
    "\n",
    "Assign weights accroding to the clusters' sizes. Cluster weight = `ln(cluster size) / ln(minimal cluster size)`. Clustering helps:\n",
    "\n",
    "<img src=\"loss/loss_x_dense_onehot_noscale_clust5.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "## Learning\n",
    "\n",
    "### Straightforward learning\n",
    "\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### Change learning rate\n",
    "\n",
    "Factor 0.3, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor03_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 3\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience3_1200it.png\" width=\"80%\">\n",
    "\n",
    "Factor 0.1, patience 6\n",
    "<img src=\"loss/loss_x_densepos_4_4_comparison_clust_and_onehot_changelr_factor01_patience6_1200it.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "### Add putative sequences to batches\n",
    "\n",
    "??? (to add noise)\n",
    "\n",
    "\n",
    "## Post-analysis\n",
    "\n",
    "### Ensembling\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1-dimensional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check if scaling works better than no-transformation\n",
    "\n",
    "### Per-column scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hist_list = {}\n",
    "# model_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# m_0 = pepm.train_model(MAX_POS, 5, \"x\", [128,64], 4, 4, 200, hist_list, model_list)\n",
    "# m_1 = pepm.train_model(MAX_POS, 5, \"x\", [128,64,64], 6, 6, 200, hist_list, model_list, \"col\", \"abs\")\n",
    "# m_2 = pepm.train_model(MAX_POS, 5, \"x\", [128,64], 4, 4, 500, hist_list, model_list, \"col\", \"abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "# df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "# X_cdr, y_cdr = to_vec_onehot(df_cdr, 4, 4)\n",
    "# X_can, y_can = to_vec_onehot(df_can, 4, 4)\n",
    "# print(\"cdr\", mean_squared_error(y_cdr, m_0.predict(X_cdr)))\n",
    "# print(\"can\", mean_squared_error(y_can, m_0.predict(X_can)))\n",
    "\n",
    "# # print(\"cdr\", tr_pred_col(\"data/cdr_coord_x.csv.gz\", MinMaxScaler, m_mm_col, 4, 4))\n",
    "# # print(\"can\", tr_pred_col(\"data/can_coord_x.csv.gz\", MinMaxScaler, m_mm_col, 4, 4))\n",
    "\n",
    "# print(\"cdr\", tr_pred_col(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler, best_models_list[\"left4_right4.128-64-64.col_abs.clust_5\"], 4, 4))\n",
    "# print(\"can\", tr_pred_col(\"data/can_coord_x.csv.gz\", MaxAbsScaler, best_models_list[\"left4_right4.128-64-64.col_abs.clust_5\"], 4, 4))\n",
    "\n",
    "\n",
    "# # batch=64\n",
    "# # cdr 1.47792\n",
    "# # can 0.113192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overall scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hist_scale = {}\n",
    "# m_no = train_models(\"x\", [128,64], 4, 4, 2000, hist_scale)\n",
    "# m_mm_all = train_models_scale_all(\"x\", [128,64], 4, 4, 2000, hist_scale, \"mm\")\n",
    "# m_abs_all = train_models_scale_all(\"x\", [128,64], 4, 4, 2000, hist_scale, \"abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "# df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "# X_cdr, y_cdr = to_vec_onehot(df_cdr, 4, 4)\n",
    "# X_can, y_can = to_vec_onehot(df_can, 4, 4)\n",
    "# print(\"cdr\", mean_squared_error(y_cdr, m_no.predict(X_cdr)))\n",
    "# print(\"can\", mean_squared_error(y_can, m_no.predict(X_can)))\n",
    "\n",
    "# print(\"cdr\", tr_pred(\"data/cdr_coord_x.csv.gz\", MinMaxScaler(), m_mm_all))\n",
    "# print(\"can\", tr_pred(\"data/can_coord_x.csv.gz\", MinMaxScaler(), m_mm_all))\n",
    "\n",
    "# print(\"cdr\", tr_pred(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all))\n",
    "# print(\"can\", tr_pred(\"data/can_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all))\n",
    "\n",
    "\n",
    "# # cdr 1.61775\n",
    "# # can 0.0993797\n",
    "# # cdr 2.27693\n",
    "# # can 0.105339\n",
    "# # cdr 1.96837\n",
    "# # can 0.0973526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find which windows and layer sizes are the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru.l4_r4.32-32-32.no_no.onehot\t"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from pep2space import model as pepmodel\n",
    "importlib.reload(pep2space.preprocess)\n",
    "pepmodel = importlib.reload(pep2space.model)\n",
    "\n",
    "best_models = [(4,4)]\n",
    "# best_layers = [[128, 64]]\n",
    "best_layers = [[32, 32, 32]]\n",
    "\n",
    "best_hist = {}\n",
    "best_models_list = {}\n",
    "\n",
    "for l,r in best_models:\n",
    "    for layers in best_layers:\n",
    "#         pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1600, best_hist, best_models_list, model_type=\"dense\")\n",
    "#         pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1600, best_hist, best_models_list, features = \"omega\", model_type=\"dense\")\n",
    "#         pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1600, best_hist, best_models_list, model_type=\"dense_pos\")\n",
    "#         pep.model.train_model(MAX_POS, 0, \"x\", layers, l, r, 1600, best_hist, best_models_list, features = \"omega\", model_type=\"dense_pos\")\n",
    "#         pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1600, best_hist, best_models_list, model_type=\"dense_poslen\")\n",
    "        pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, model_type=\"gru\")\n",
    "        pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, model_type=\"lstm\")\n",
    "        pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, features = \"omega\", model_type=\"gru\")\n",
    "        pepmodel.train_model(MAX_POS, 0, \"x\", layers, l, r, 1200, best_hist, best_models_list, features = \"omega\", model_type=\"lstm\")\n",
    "        \n",
    "print(best_hist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# import keras\n",
    "# import keras.utils\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# model = best_models_list[\"dense_poslen.l4_r4.128-64.no_no.onehot\"]\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 1\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:10]\n",
    "\n",
    "# for i, h in enumerate(sorted(cur_hist.keys())):\n",
    "for i, (h, _) in enumerate(best_models):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/__loss_x_rnn_4_4_comparison_noclust_1200it.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = best_models_list[\"dense_poslen.l4_r4.128-64.no_no.omega\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model expects 3 input arrays, but only received one array. Found: array with shape (828, 180)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-90b55359056e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_figwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MinMaxScaler, m_mm_col)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler, m_abs_col)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     98\u001b[0m             raise ValueError('The model expects ' + str(len(names)) +\n\u001b[1;32m     99\u001b[0m                              \u001b[0;34m' input arrays, but only received one array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                              'Found: array with shape ' + str(data.shape))\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The model expects 3 input arrays, but only received one array. Found: array with shape (828, 180)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAD8CAYAAAB+Q1lpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgAAwFD+H60x0kVlhSVbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fceec256fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_pred(df, pred, ax, title):\n",
    "    trans = pred.reshape((len(df),MAX_POS))\n",
    "    for i in range(len(df)):\n",
    "        ax.plot(range(MAX_POS), df.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "        ax.plot(range(MAX_POS), trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.8, label=\"pred\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    \n",
    "# Predicted and real coordinates\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "X_cdr, y_cdr = pep.preprocess.onehot_omega(df_cdr, 4, 4, MAX_POS)\n",
    "X_can, y_can = pep.preprocess.onehot_omega(df_can, 4, 4, MAX_POS)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "\n",
    "pred = model.predict(X_cdr)\n",
    "# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MinMaxScaler, m_mm_col)\n",
    "# _, pred = get_true_pred_col(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler, m_abs_col)\n",
    "# _, pred = get_true_pred_all(\"data/cdr_coord_x.csv.gz\", MinMaxScaler(), m_mm_all)\n",
    "# _, pred = get_true_pred_all(\"data/cdr_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all)\n",
    "plot_pred(df_cdr, pred, ax[0], \"CDR\")\n",
    "\n",
    "pred = model.predict(X_can)\n",
    "# _, pred = get_true_pred_col(\"data/can_coord_x.csv.gz\", MinMaxScaler, m_mm_col)\n",
    "# _, pred = get_true_pred_col(\"data/can_coord_x.csv.gz\", MaxAbsScaler, m_abs_col)\n",
    "# _, pred = get_true_pred_all(\"data/can_coord_x.csv.gz\", MinMaxScaler(), m_mm_all)\n",
    "# _, pred = get_true_pred_all(\"data/can_coord_x.csv.gz\", MaxAbsScaler(), m_abs_all)\n",
    "plot_pred(df_can, pred, ax[1], \"Canonical\")\n",
    "\n",
    "# plt.savefig(\"pred_dense_onehot_no.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_mm_col.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_mm_all.png\")\n",
    "# plt.savefig(\"pred_dense_onehot_abs_col.png\")\n",
    "plt.savefig(\"pred_tmp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-dimensional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_models(coord, layers, left_window, right_window, n_epochs, hist):\n",
    "    model_name = \"left\" + str(left_window) + \"_right\" + str(right_window)\n",
    "    if model_name not in hist:\n",
    "        df_cdr = pd.read_csv(\"data/cdr_coord_\" + coord[0] + \".csv.gz\")\n",
    "        df_can = pd.read_csv(\"data/can_coord_\" + coord[0] + \".csv.gz\")\n",
    "        \n",
    "        df_cdr_add = pd.read_csv(\"data/cdr_coord_\" + coord[1] + \".csv.gz\")\n",
    "        df_can_add = pd.read_csv(\"data/can_coord_\" + coord[1] + \".csv.gz\")\n",
    "\n",
    "        X_can, y_can = to_vec_onehot(df_can, df_can_add, left_window, right_window)\n",
    "        X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, left_window, right_window)\n",
    "\n",
    "        model = dense_model((20*(right_window+left_window+1),), 2, layers)\n",
    "\n",
    "        hist[model_name] = model.fit(X_can, y_can, batch_size=128, epochs=n_epochs, verbose=0, validation_data=(X_cdr, y_cdr))\n",
    "\n",
    "\n",
    "# hist = {}\n",
    "# for left_window in range(8):\n",
    "#     for right_window in range(8):\n",
    "#         train_models(\"x\", left_window, right_window, 2000, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_models = [(3,3), (4,4), (5,5), (6,6)]\n",
    "\n",
    "best_hist = {}\n",
    "for l,r in best_models:\n",
    "    train_models([\"x\", \"y\"], [128,64], l, r, 2000, best_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "def smooth(vec):\n",
    "    res = []\n",
    "    window = 10\n",
    "    step = 1\n",
    "    for i in range(window, len(vec)-window, step):\n",
    "        res.append(np.mean(vec[i-window:i+window+1]))\n",
    "    return res\n",
    "\n",
    "cur_hist = best_hist\n",
    "best_models = sorted([(h, np.mean(cur_hist[h].history[\"val_loss\"][-5:])) for h in cur_hist], key=lambda x: x[1])[:8]\n",
    "\n",
    "for i, (h, _) in enumerate(sorted(best_models)):\n",
    "    ax[0].plot(np.log2(smooth(cur_hist[h].history[\"loss\"][100:])), label=h)\n",
    "    ax[1].plot(np.log2(smooth(cur_hist[h].history[\"val_loss\"][100:])), label=h)\n",
    "\n",
    "\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"val\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.savefig(\"loss/loss_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_vec_onehot(df, df_add, left_window, right_window):\n",
    "    X = np.zeros((len(df)*MAX_POS, (left_window+right_window+1) * len(chars)), dtype=bool)\n",
    "    y = np.zeros((len(df)*MAX_POS, 2), dtype=np.float32)\n",
    "    for seq_i, seq in enumerate(df[\"sequence\"]):\n",
    "        seq = \"X\"*left_window + seq + \"X\"*right_window\n",
    "        for index, target_pos in enumerate(range(left_window + 1, len(seq) - right_window)):\n",
    "            target_aa = seq[target_pos]\n",
    "            for amb_pos, amb_aa in enumerate(seq[target_pos-left_window : target_pos+right_window+1]):\n",
    "                if amb_aa != \"X\":\n",
    "                    X[seq_i*MAX_POS + index, amb_pos*len(chars):(amb_pos+1)*len(chars)] = one_hot[amb_aa]\n",
    "            y[seq_i*MAX_POS + index, 0] = df[[4 + index]].iloc[seq_i]\n",
    "            y[seq_i*MAX_POS + index, 1] = df_add[[4 + index]].iloc[seq_i]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "\n",
    "df_cdr_add = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "df_can_add = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "\n",
    "X_can, y_can = to_vec_onehot(df_can, df_can_add, 5, 5)\n",
    "X_cdr, y_cdr = to_vec_onehot(df_cdr, df_cdr_add, 5, 5)\n",
    "\n",
    "model = dense_model((20*(5+5+1),), 2, [128, 64])\n",
    "\n",
    "model.fit(X_can, y_can, batch_size=128, epochs=2000, verbose=0, validation_data=(X_cdr, y_cdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predicted and real coordinates\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "\n",
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[0][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][0].set_title(\"CDR X\")\n",
    "\n",
    "df_cdr = pd.read_csv(\"data/cdr_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_cdr),12))\n",
    "for i in range(len(df_cdr)):\n",
    "    ax[1][0].plot(range(12), df_cdr.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][0].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][0].set_title(\"CDR Y\")\n",
    "\n",
    "    \n",
    "pred = model.predict(X_can)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_x.csv.gz\")\n",
    "trans = pred_x.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[0][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[0][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[0][1].set_title(\"Canonical X\")\n",
    "\n",
    "df_can = pd.read_csv(\"data/can_coord_y.csv.gz\")\n",
    "trans = pred_y.reshape((len(df_can),12))\n",
    "for i in range(len(df_can)):\n",
    "    ax[1][1].plot(range(12), df_can.iloc[i,4:16], c=\"black\", alpha=.5, label=\"real\")\n",
    "    ax[1][1].plot(trans[i,:], c = \"red\", linestyle=\"dotted\", alpha=.7, label=\"pred\")\n",
    "ax[1][1].set_title(\"Canonical Y\")\n",
    "\n",
    "plt.savefig(\"pred/pred_xy_dense2layer_onehot_2000it.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_cdr)\n",
    "pred_x, pred_y = pred[:,0], pred[:,1]\n",
    "pred_x[11]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
